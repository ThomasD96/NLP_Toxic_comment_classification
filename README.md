# Toxic Comment Classification Challenge: Kaggle


The dataset consists of a large set of user comments from Wikipediaâ€™s talk page edits. Some of the users, unfortuantely resort to threats, and abusive behaviour and racism to get their point across. Each of the comments in this dataset is labelled as toxic, severee toxic, obscene, threat, identity hate, or clean.

This is a classic text classification problem, where one is given a corpus of text documents with labelled classes, and one has to perform supervised machine learning to first train the data, and then classify unseen documents. This will help the mods to hopefully weed out hateful comments in the future from the comment section with the help of machine learning.

[Link to the Kaggle competition page](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)

